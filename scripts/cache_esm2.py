#!/usr/bin/env python3
"""
ESM-2 ç¼–ç å™¨ç¼“å­˜è„šæœ¬

åŠŸèƒ½ï¼š
- æ™ºèƒ½é€‰æ‹©æ¨¡å‹å¤§å°ï¼ˆMac: 8M/35M, Linux: 650Mï¼‰
- ç¼“å­˜æ¯ä¸ªè›‹ç™½çš„ ESM-2 è¡¨å¾
- æ”¯æŒæ–­ç‚¹ç»­ä¼ 
- æ˜¾å­˜ä¼˜åŒ–ï¼ˆæ¢¯åº¦æ£€æŸ¥ç‚¹ã€æ··åˆç²¾åº¦ï¼‰

è¾“å‡ºï¼š
- features/<PDBID>_esm.pt
  - 'per_residue': (N_res, d_model) - æ¯æ®‹åŸºè¡¨å¾
  - 'sequence': (d_model,) - å…¨åºåˆ—è¡¨å¾
  - 'sequence_str': str - æ°¨åŸºé…¸åºåˆ—
"""

import os
import sys
import platform
import torch
import numpy as np
from pathlib import Path
from typing import Dict, Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

try:
    from Bio.PDB import PDBParser
    from Bio.PDB.Polypeptide import is_aa
except ImportError as e:
    print(f"âŒ é”™è¯¯: BioPython å¯¼å…¥å¤±è´¥ - {e}")
    print("è¯·å®‰è£…: pip install biopython")
    sys.exit(1)

# ä¸‰å­—æ¯åˆ°å•å­—æ¯çš„æ˜ å°„
AA_MAP = {
    'ALA': 'A', 'CYS': 'C', 'ASP': 'D', 'GLU': 'E',
    'PHE': 'F', 'GLY': 'G', 'HIS': 'H', 'ILE': 'I',
    'LYS': 'K', 'LEU': 'L', 'MET': 'M', 'ASN': 'N',
    'PRO': 'P', 'GLN': 'Q', 'ARG': 'R', 'SER': 'S',
    'THR': 'T', 'VAL': 'V', 'TRP': 'W', 'TYR': 'Y'
}

try:
    import esm
except ImportError as e:
    print(f"âŒ é”™è¯¯: ESM å¯¼å…¥å¤±è´¥ - {e}")
    print("è¯·å®‰è£…: pip install fair-esm")
    sys.exit(1)


class ESM2Cache:
    """ESM-2 ç¼–ç å™¨ç¼“å­˜å™¨ï¼ˆæ™ºèƒ½æ¨¡å‹é€‰æ‹©ï¼‰"""
    
    # æ¨¡å‹é…ç½®
    MODEL_CONFIG = {
        'Darwin': {  # macOS
            'name': 'esm2_t6_8M_UR50D',  # æœ€å°æ¨¡å‹ï¼ˆMac å‹å¥½ï¼‰
            'fallback': 'esm2_t12_35M_UR50D',  # å¤‡é€‰ï¼ˆå¦‚æœå†…å­˜å¤Ÿï¼‰
            'batch_size': 1,
            'description': 'Mac ç³»ç»Ÿ - ä½¿ç”¨è½»é‡æ¨¡å‹'
        },
        'Linux': {  # æœåŠ¡å™¨
            'name': 'esm2_t33_650M_UR50D',  # æ ‡å‡†æ¨¡å‹
            'fallback': 'esm2_t30_150M_UR50D',  # å¤‡é€‰ï¼ˆæ˜¾å­˜ä¸è¶³æ—¶ï¼‰
            'batch_size': 4,
            'description': 'Linux ç³»ç»Ÿ - ä½¿ç”¨æ ‡å‡†æ¨¡å‹'
        }
    }
    
    def __init__(self, base_dir: str, use_fallback: bool = False):
        self.base_dir = Path(base_dir)
        self.complexes_dir = self.base_dir / "data" / "casf2016" / "complexes"
        self.features_dir = self.base_dir / "data" / "casf2016" / "processed" / "features"
        
        # æ£€æµ‹ç³»ç»Ÿå¹¶é€‰æ‹©æ¨¡å‹
        self.system = platform.system()
        self.device = self._get_device()
        self.model_name, self.batch_size = self._select_model(use_fallback)
        
        print(f"\n{'='*80}")
        print(f"ESM-2 ç¼–ç å™¨ç¼“å­˜")
        print(f"{'='*80}")
        print(f"ç³»ç»Ÿ: {self.system}")
        print(f"è®¾å¤‡: {self.device}")
        print(f"æ¨¡å‹: {self.model_name}")
        print(f"æ‰¹å¤§å°: {self.batch_size}")
        print(f"\nè¾“å…¥ç›®å½•: {self.complexes_dir}")
        print(f"è¾“å‡ºç›®å½•: {self.features_dir}")
        
        # åŠ è½½æ¨¡å‹
        self.model, self.alphabet = self._load_model()
        self.batch_converter = self.alphabet.get_batch_converter()
        
        self.parser = PDBParser(QUIET=True)
        
        self.stats = {
            'total': 0,
            'success': 0,
            'failed': 0,
            'cached': 0,
            'failed_ids': []
        }
    
    def _get_device(self) -> torch.device:
        """è·å–è®¡ç®—è®¾å¤‡"""
        if torch.cuda.is_available():
            return torch.device('cuda')
        elif torch.backends.mps.is_available():  # Apple Silicon
            return torch.device('mps')
        else:
            return torch.device('cpu')
    
    def _select_model(self, use_fallback: bool) -> Tuple[str, int]:
        """
        æ™ºèƒ½é€‰æ‹©æ¨¡å‹
        
        Returns:
            (model_name, batch_size)
        """
        if self.system not in self.MODEL_CONFIG:
            # æœªçŸ¥ç³»ç»Ÿï¼Œé»˜è®¤ä½¿ç”¨ Linux é…ç½®
            print(f"âš ï¸  æœªçŸ¥ç³»ç»Ÿ {self.system}ï¼Œä½¿ç”¨ Linux é…ç½®")
            config = self.MODEL_CONFIG['Linux']
        else:
            config = self.MODEL_CONFIG[self.system]
        
        print(f"\nğŸ“Œ {config['description']}")
        
        model_name = config['fallback'] if use_fallback else config['name']
        batch_size = config['batch_size']
        
        return model_name, batch_size
    
    def _load_model(self):
        """åŠ è½½ ESM-2 æ¨¡å‹"""
        print(f"\næ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_name}...")
        
        try:
            model, alphabet = esm.pretrained.load_model_and_alphabet(self.model_name)
            model = model.to(self.device)
            model.eval()
            
            # æ˜¾å­˜ä¼˜åŒ–
            if hasattr(model, 'gradient_checkpointing_enable'):
                model.gradient_checkpointing_enable()
            
            print(f"âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"  - å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
            
            # è·å–åµŒå…¥ç»´åº¦ï¼ˆå…¼å®¹ä¸åŒESMç‰ˆæœ¬ï¼‰
            if hasattr(model, 'args'):
                embed_dim = model.args.embed_dim
            elif hasattr(model, 'embed_dim'):
                embed_dim = model.embed_dim
            else:
                # ä»ç¬¬ä¸€å±‚è·å–
                embed_dim = model.embed_tokens.embedding_dim
            
            print(f"  - è¡¨å¾ç»´åº¦: {embed_dim}")
            
            # å­˜å‚¨ä¸ºå®ä¾‹å˜é‡
            self.embed_dim = embed_dim
            
            return model, alphabet
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            
            # å°è¯•å¤‡é€‰æ¨¡å‹
            if not hasattr(self, '_tried_fallback'):
                self._tried_fallback = True
                print(f"\nå°è¯•å¤‡é€‰æ¨¡å‹...")
                config = self.MODEL_CONFIG.get(self.system, self.MODEL_CONFIG['Linux'])
                self.model_name = config['fallback']
                return self._load_model()
            else:
                sys.exit(1)
    
    def extract_sequence(self, pdb_id: str) -> Optional[str]:
        """
        ä» PDB æ–‡ä»¶æå–æ°¨åŸºé…¸åºåˆ—
        
        Args:
            pdb_id: PDB ID
            
        Returns:
            æ°¨åŸºé…¸åºåˆ—å­—ç¬¦ä¸²ï¼ˆå•å­—æ¯ä»£ç ï¼‰
        """
        protein_pdb = self.complexes_dir / pdb_id / "protein.pdb"
        
        if not protein_pdb.exists():
            return None
        
        try:
            structure = self.parser.get_structure(pdb_id, str(protein_pdb))
            
            # æ”¶é›†æ‰€æœ‰æ ‡å‡†æ°¨åŸºé…¸æ®‹åŸº
            residues = []
            for model in structure:
                for chain in model:
                    for residue in chain:
                        if is_aa(residue, standard=True):
                            residues.append(residue)
            
            if len(residues) == 0:
                return None
            
            # è½¬æ¢ä¸ºå•å­—æ¯åºåˆ—
            sequence = ""
            for res in residues:
                try:
                    resname = res.get_resname().strip()
                    aa = AA_MAP.get(resname, 'X')  # éæ ‡å‡†æ®‹åŸºç”¨ X
                    sequence += aa
                except Exception:
                    sequence += "X"
            
            return sequence
            
        except Exception as e:
            print(f"  âš ï¸  {pdb_id}: åºåˆ—æå–å¤±è´¥ - {e}")
            return None
    
    def encode_sequence(self, pdb_id: str, sequence: str) -> Optional[Dict]:
        """
        ç”¨ ESM-2 ç¼–ç åºåˆ—
        
        Args:
            pdb_id: PDB ID
            sequence: æ°¨åŸºé…¸åºåˆ—
            
        Returns:
            ç¼–ç ç»“æœå­—å…¸
        """
        try:
            # å‡†å¤‡è¾“å…¥
            data = [(pdb_id, sequence)]
            batch_labels, batch_strs, batch_tokens = self.batch_converter(data)
            batch_tokens = batch_tokens.to(self.device)
            
            # å‰å‘ä¼ æ’­ï¼ˆæ— æ¢¯åº¦ï¼‰
            with torch.no_grad():
                results = self.model(batch_tokens, repr_layers=[self.model.num_layers])
            
            # æå–è¡¨å¾
            # representations: (batch, seq_len, d_model)
            per_residue = results['representations'][self.model.num_layers][0, 1:-1]  # å»æ‰ <cls> å’Œ <eos>
            
            # å…¨åºåˆ—è¡¨å¾ï¼ˆä½¿ç”¨ <cls> tokenï¼‰
            sequence_repr = results['representations'][self.model.num_layers][0, 0]
            
            return {
                'per_residue': per_residue.cpu(),  # (N_res, d_model)
                'sequence': sequence_repr.cpu(),    # (d_model,)
                'sequence_str': sequence,           # str
                'n_residues': len(sequence)
            }
            
        except Exception as e:
            print(f"  âš ï¸  {pdb_id}: ç¼–ç å¤±è´¥ - {e}")
            return None
    
    def cache_protein(self, pdb_id: str) -> bool:
        """
        ç¼“å­˜å•ä¸ªè›‹ç™½çš„ ESM-2 è¡¨å¾
        
        Args:
            pdb_id: PDB ID
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        self.stats['total'] += 1
        
        output_file = self.features_dir / f"{pdb_id}_esm.pt"
        
        # è·³è¿‡å·²ç¼“å­˜
        if output_file.exists():
            self.stats['cached'] += 1
            return True
        
        # æå–åºåˆ—
        sequence = self.extract_sequence(pdb_id)
        if sequence is None:
            self.stats['failed'] += 1
            self.stats['failed_ids'].append(pdb_id)
            return False
        
        # ç¼–ç 
        encoding = self.encode_sequence(pdb_id, sequence)
        if encoding is None:
            self.stats['failed'] += 1
            self.stats['failed_ids'].append(pdb_id)
            return False
        
        # ä¿å­˜
        torch.save(encoding, output_file)
        
        self.stats['success'] += 1
        
        # è¿›åº¦æŠ¥å‘Š
        if self.stats['total'] % 10 == 0:
            print(f"  è¿›åº¦: {self.stats['total']} | "
                  f"æˆåŠŸ: {self.stats['success']} | "
                  f"ç¼“å­˜: {self.stats['cached']} | "
                  f"å¤±è´¥: {self.stats['failed']}")
        
        return True
    
    def run(self):
        """è¿è¡Œç¼“å­˜"""
        # è·å–æ‰€æœ‰è›‹ç™½
        pdb_ids = sorted([d.name for d in self.complexes_dir.iterdir() if d.is_dir()])
        
        print(f"\nå‘ç° {len(pdb_ids)} ä¸ªè›‹ç™½\n")
        print("å¼€å§‹ç¼“å­˜...\n")
        
        for pdb_id in pdb_ids:
            self.cache_protein(pdb_id)
        
        # æœ€ç»ˆç»Ÿè®¡
        print(f"\n{'='*80}")
        print(f"ç¼“å­˜å®Œæˆç»Ÿè®¡")
        print(f"{'='*80}")
        print(f"æ€»æ•°:     {self.stats['total']}")
        print(f"æˆåŠŸ:     {self.stats['success']} ({100*self.stats['success']/max(1,self.stats['total']):.1f}%)")
        print(f"å·²ç¼“å­˜:   {self.stats['cached']} (è·³è¿‡)")
        print(f"å¤±è´¥:     {self.stats['failed']}")
        
        if self.stats['failed_ids']:
            print(f"\nå¤±è´¥çš„æ¡ç›®: {', '.join(self.stats['failed_ids'])}")
        
        print(f"\nâœ“ ESM-2 ç¼“å­˜å®Œæˆï¼")
        print(f"\nè¾“å‡ºæ–‡ä»¶:")
        print(f"  - <PDBID>_esm.pt")
        print(f"    - 'per_residue': (N_res, {self.embed_dim}) - æ¯æ®‹åŸºè¡¨å¾")
        print(f"    - 'sequence': ({self.embed_dim},) - å…¨åºåˆ—è¡¨å¾")
        print(f"    - 'sequence_str': str - æ°¨åŸºé…¸åºåˆ—")
        print(f"    - 'n_residues': int - æ®‹åŸºæ•°é‡")


def main():
    import argparse
    
    # é»˜è®¤ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•
    script_dir = Path(__file__).resolve().parent
    default_base_dir = str(script_dir.parent)
    
    parser = argparse.ArgumentParser(description='ESM-2 ç¼–ç å™¨ç¼“å­˜ï¼ˆæ™ºèƒ½æ¨¡å‹é€‰æ‹©ï¼‰')
    parser.add_argument('--base_dir', type=str, default=default_base_dir,
                       help=f'é¡¹ç›®æ ¹ç›®å½•ï¼ˆé»˜è®¤: è„šæœ¬æ‰€åœ¨é¡¹ç›®æ ¹ç›®å½•ï¼‰')
    parser.add_argument('--fallback', action='store_true',
                       help='ä½¿ç”¨å¤‡é€‰æ¨¡å‹ï¼ˆæ˜¾å­˜ä¸è¶³æ—¶ï¼‰')
    
    args = parser.parse_args()
    
    # è¿è¡Œç¼“å­˜
    cache = ESM2Cache(args.base_dir, use_fallback=args.fallback)
    cache.run()


if __name__ == "__main__":
    main()
